<?xml version="1.0" encoding="UTF-8"?><oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd"><dc:identifier>http://zaguan.unizar.es/record/8031</dc:identifier><dc:language>spa</dc:language><dc:creator>Martínez Millán, Daniel</dc:creator><dc:creator>Marco Rubio, Javier</dc:creator><dc:creator>Serón Arbeloa, Francisco José</dc:creator><dc:title>Interface de usuario multimodal asistido con agente virtual</dc:title><dc:description>En este Proyecto Fin de Carrera se ha desarrollado una interfaz multimodal asistida con un agente virtual 3D, sobre la que estudiantes de educación secundaria pueden realizar consultas para obtener información de diversos temas científico-mecánicos disponibles en la Wikipedia, y obtener información de la Web utilizando para ello diversas Web API disponibles en la red. Este proyecto se enmarca dentro del proyecto Alfa III GAVIOTA de la Unión Europea. Como herramienta multimodal, la aplicación permite que las consultas que se realicen puedan efectuarse mediante interacción tradicional, utilizando dispositivos de entrada convencionales como el ratón, o por voz mediante lenguaje natural. Además la aplicación desarrollada muestra la información recibida de los servicios Web integrados, en forma de hipertexto, multimedia, y síntesis de voz. Para permitir la comunicación multimodal se ha desarrollado una interfaz WIMP (Windows, Icons, Menus, Pointer) para la interacción tradicional sobre la que se incorpora el agente 3D, y para la comunicación por voz se ha integrado un reconocedor de voz que se apoya en la utilización de gramáticas ABNF y la herramienta Loquendo ASR. Para obtener la gramática que contiene las reglas que emplea el reconocedor de voz en la interacción, se han utilizado herramientas externas que permiten validar la correcta definición de esas reglas y el alcance que tienen en el reconocimiento. Del mismo modo permiten comprobar las interpretaciones semánticas de las consultas, que serán utilizadas para llamar a los procedimientos específicos especializados en ese tipo de solicitudes. Una vez obtenida la semántica de una consulta, se procede al análisis de ésta, para reconocer el tipo de solicitud realizada y la información específica proporcionada. Posteriormente se realiza la comunicación con los servicios Web disponibles, de los que se reciben los datos solicitados que hay que analizar para adecuarla a la salida de la interfaz, y así mostrar la información ya sea utilizando la interfaz WIMP o a través de síntesis de voz, utilizando para ello la herramienta Loquendo TTS. Para permitir la simulación del habla del agente 3D, se ha desarrollado un analizador de símbolos fonéticos X-SAMPA, que convierte estos símbolos en información fácilmente interpretable por el agente 3D, permitiéndole así poder realizar una representación labial correcta de cada uno de los fonemas posibles. La interfaz WIMP muestra la información recibida por los servicios Web, y permite visualizar imágenes recibidas, reproducir elementos multimedia, y acceder a las páginas web que contienen la información completa solicitada. Además de las funcionalidades presentadas, la herramienta desarrollada destaca por disponer de las herramientas necesarias para que nuevas funcionalidades puedan ser incorporadas de forma sencilla, y permitir que pueda ser utilizada en futuros proyectos sobre interacción multimodal.</dc:description><dc:publisher>Universidad de Zaragoza</dc:publisher><dc:identifier>TAZ-PFC-2012-406</dc:identifier><dc:identifier>oai:zaguan.unizar.es:8031</dc:identifier><dc:date>2012</dc:date></oai_dc:dc>